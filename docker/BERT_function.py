# -*- coding: utf-8 -*-
"""BERT_function.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xdh6GEyUiQxQToqI7sM1KBh7w3CAvEWS
"""

# BERT_function.py

from transformers import AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import Dataset, DataLoader
import torch

class ReviewDataset(Dataset):
    def __init__(self, examples, labels, tokenizer):
        self.examples = examples
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.examples)

    def __getitem__(self, idx):
        example = self.examples[idx]

        # Tokenize the title and label
        inputs = self.tokenizer.encode_plus(
            example,
            add_special_tokens=True,
            padding="max_length",
            max_length=512,
            truncation=True,
            return_tensors="pt"
        )

        input_ids = inputs["input_ids"].squeeze()
        attention_mask = inputs["attention_mask"].squeeze()

        return input_ids, attention_mask

def evaluate_model_with_fasttext(model_path, new_data, batch_size=1):
    tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
    model = AutoModelForSequenceClassification.from_pretrained(model_path)

    dataset = ReviewDataset(new_data, tokenizer)
    data_loader = DataLoader(dataset, batch_size=batch_size)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    predicted_labels = []

    for inputs, attention_mask in data_loader:
        inputs = inputs.to(device)
        attention_mask = attention_mask.to(device)

        with torch.no_grad():
            outputs = model(inputs, attention_mask=attention_mask)
            _, predicted = torch.max(outputs.logits, dim=1)

            predicted_labels.extend(predicted.tolist())

    return predicted_labels

if __name__ == "__main__":
    # Main function to evaluate the model with new data
    model_path = "model path here"  # Path to the trained model
    new_data = ["This product performed exactly as expected, except for when it broke. Won't buy another."]  # Provide examples of new data for evaluation

    predicted_labels = evaluate_model_with_fasttext(model_path, tokenizer_name, new_data_examples, new_data_labels)